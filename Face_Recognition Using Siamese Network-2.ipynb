{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, cv2, os\n",
    "import pickle\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import face_recognition\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth=True\n",
    "sess = tf.compat.v1.Session(config=config)\n",
    "\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import Input, Lambda, Dense, Dropout, LSTM\n",
    "from keras.layers import Subtract, Convolution2D, MaxPooling2D, Flatten, GlobalMaxPooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from efficientnet.tfkeras import EfficientNetB3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'dataset/train/'\n",
    "data = []\n",
    "labels = []\n",
    "for folders in tqdm(os.listdir(path)):\n",
    "    folder = path + folders\n",
    "    for files in os.listdir(folder):\n",
    "        img = folder + '/' + files\n",
    "        image = cv2.imread(img)                \n",
    "        image = cv2.resize(image,(64,64))\n",
    "        data.append(image)\n",
    "        labels.append(int(folders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array(data)\n",
    "labels = np.array(labels)\n",
    "print(data.shape,labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pairs(data, labels):\n",
    "    pairData = []\n",
    "    pairLabels = []\n",
    "    numClasses = len(np.unique(labels))\n",
    "    idx = [np.where(labels == i)[0] for i in range(0, numClasses)]\n",
    "    for idxA in range(len(data)):\n",
    "        currentAudio = data[idxA]\n",
    "        label = labels[idxA]\n",
    "        idxB = np.random.choice(idx[label])\n",
    "        posData = data[idxB]\n",
    "        pairData.append([currentAudio, posData])\n",
    "        pairLabels.append([1])\n",
    "        negIdx = np.where(labels != label)[0]\n",
    "        negData = data[np.random.choice(negIdx)]\n",
    "        pairData.append([currentAudio, negData])\n",
    "        pairLabels.append([0])\n",
    "    return (np.array(pairData), np.array(pairLabels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X, Y = make_pairs(data, labels)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dim = X.shape[2:]\n",
    "print(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def siamese_model(input_dim):\n",
    "    #base_model = EfficientNetB3(weights='imagenet', include_top=True, input_shape=(300, 300, 3))\n",
    "    #base_model = ResNet50(weights='imagenet', include_top=True, input_shape=input_dim)\n",
    "    base_model = VGG16(include_top=False, input_shape=input_dim)\n",
    "    for layers in base_model.layers:\n",
    "        layers.trainable = False\n",
    "    base_model = Model(inputs = base_model.input, outputs = base_model.layers[-2].output)\n",
    "    base_model.summary()\n",
    "    return base_model\n",
    "\n",
    "feature_model = siamese_model(input_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = input_dim\n",
    "img_a_in = Input(shape = input_shape, name = 'ImageA_Input')\n",
    "img_b_in = Input(shape = input_shape, name = 'ImageB_Input')\n",
    "\n",
    "img_a_feat = feature_model(img_a_in)\n",
    "img_b_feat = feature_model(img_b_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_a_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_distance(vectors):\n",
    "    (featsA, featsB) = vectors\n",
    "    sumSquared = K.sum(K.square(featsA - featsB), axis=1,keepdims=True)\n",
    "    return K.sqrt(K.maximum(sumSquared, K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import concatenate,BatchNormalization,Activation  \n",
    "\n",
    "combined_features = concatenate([img_a_feat, img_b_feat], name = 'merge_features')\n",
    "combined_features = Dense(256, activation = 'relu')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "combined_features = Dropout(0.2)(combined_features)\n",
    "combined_features = Dense(128, activation = 'relu')(combined_features)\n",
    "combined_features = BatchNormalization()(combined_features)\n",
    "distance = Activation('relu')(combined_features)\n",
    "\n",
    "#distance = Lambda(euclidean_distance)([img_a_feat, img_b_feat])\n",
    "\n",
    "combined_features = Dense(1, activation = 'sigmoid')(distance)\n",
    "similarity_model = Model(inputs = [img_a_in, img_b_in], outputs = [combined_features], name = 'Similarity_Model')\n",
    "similarity_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.compile(loss='binary_crossentropy', optimizer=\"rmsprop\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_1 = X[:, 0]\n",
    "img2 = X[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "similarity_model.fit([img_1, img2], Y[:],batch_size=1, validation_split=0.2, verbose=1, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_model.save(\"face_siam.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "\n",
    "similarity_model = load_model(\"face_siam.h5\", custom_objects={'loss': euclidean_distance})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread(\"test/1.jpg\")\n",
    "rgb = cv2.cvtColor(img1, cv2.COLOR_BGR2RGB) \n",
    "face_locations = face_recognition.face_locations(rgb)\n",
    "for face_location in face_locations:  \n",
    "    top, right, bottom, left = face_location\n",
    "    face1 = img1[top:bottom, left:right] \n",
    "    cv2.imwrite(\"face1.jpg\", face1)\n",
    "    face1 = cv2.resize(face1,(224,224))  \n",
    "    face1 = np.expand_dims(face1,axis=0)\n",
    "\n",
    "img2 = cv2.imread(\"test/1.jpg\")\n",
    "rgb2 = cv2.cvtColor(img2, cv2.COLOR_BGR2RGB) \n",
    "face_locations = face_recognition.face_locations(rgb2)\n",
    "for face_location in face_locations:  \n",
    "    top, right, bottom, left = face_location\n",
    "    face2 = img2[top:bottom, left:right] \n",
    "    cv2.imwrite(\"face2.jpg\", face2)\n",
    "    face2 = cv2.resize(face2,(224,224))\n",
    "    face2 = np.expand_dims(face2,axis=0)   \n",
    "\n",
    "pred = similarity_model.predict([face1, face2])[0]\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.system(\"shutdown /s /t 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
